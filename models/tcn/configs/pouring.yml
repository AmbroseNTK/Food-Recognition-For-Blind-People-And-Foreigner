# Train with Multi-View TCN.
training_strategy: 'mvtcn'

# Use the 'inception_conv_ss_fc' embedder, which has the structure:
# InceptionV3 -> 2 conv adaptation layers -> spatial softmax -> fully connected
# -> embedding.
embedder_strategy: 'inception_conv_ss_fc'

# Use npairs loss.
loss_strategy: 'npairs'

learning:
  learning_rate: 0.0001

# Set some hyperparameters for our embedder.
inception_conv_ss_fc:
  # Don't finetune the pre-trained weights.
  finetune_inception: false
  dropout:
    # Don't dropout convolutional activations.
    keep_conv: 1.0
    # Use a dropout of 0.8 on the fully connected activations.
    keep_fc: 0.8
    # Use a dropout of 0.8 on the inception activations.
    keep_pretrained: 0.8

# Size of the TCN embedding.
embedding_size: 32

data:
  raw_height: 480
  raw_width: 360
  batch_size: 32
  examples_per_sequence: 32
  num_views: 2
  preprocessing:
    # Inference-time image cropping strategy.
    eval_cropping: 'pad200'
  augmentation:
    # Do scale augmentation.
    minscale: 0.8 # When downscaling, zoom in to 80% of the central bounding box.
    maxscale: 3.0 # When upscaling, zoom out to 300% of the central bounding box.
    proportion_scaled_up: 0.5 # Proportion of the time to scale up rather than down.
    color: true # Do color augmentation.
    fast_mode: true
  # Paths to the data.
  training: '~/tcn_data/multiview-pouring/tfrecords/train'
  validation: '~/tcn_data/multiview-pouring/tfrecords/val'
  test: 'path/to/test'
  labeled:
    image_attr_keys: ['image/view0', 'image/view1', 'task']
    label_attr_keys: ['contact', 'distance', 'liquid_flowing', 'has_liquid', 'container_angle']
    validation: '~/tcn_data/multiview-pouring/monolithic-labeled/val'
    test: '~/tcn_data/multiview-pouring/monolithic-labeled/test'

logging:
  checkpoint:
    save_checkpoints_steps: 1000